<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on nishihi6</title>
    <link>https://nishihi6.github.io/blog/</link>
    <description>Recent content in Home on nishihi6</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Thu, 04 Jan 2024 23:57:28 +0900</lastBuildDate><atom:link href="https://nishihi6.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>楽しさとは #1 [Memo #005]</title>
      <link>https://nishihi6.github.io/blog/posts/memo_ent_01/</link>
      <pubDate>Thu, 04 Jan 2024 23:57:28 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/memo_ent_01/</guid>
      <description>エンターテインメント学 エンタメとは エンターテインメント（以下エンタメ）は人々を楽しませることを目的とした活動・表現である
エンタメの原点 エンタメは人類の歴史と共に進化し、文化や技術の発展に合わせて形態が変化している
初期のエンタメ（社会的結束や文化的伝承の手段） 目的 エンタメの例 文化、伝統、価値観を伝える 口承文学（物語（神話、伝説）） 未来世代に情報を伝える 壁画 社会的・宗教的な結束 音楽、ダンス 狩猟の技能を模倣して競う スポーツ、ゲーム これらのエンタメの形態が基礎となり、現代のエンタメの基本的な原則を形成している
現代のエンタメ（目的は広範かつ多様） 目的 エンタメの例 娯楽（純粋な楽しさ、笑い） コメディ映画、サーカス、テーマパーク リラクゼーション（精神的な休息） 瞑想音楽、スパ体験、自然散策 教育（学習体験） 博物館、教育番組、ドキュメンタリー映画 社会的結束（コミュニティ感の強化） スポーツ、祭り、コンサート 文化的表現（文化、伝統、価値観の表現と伝承） 民俗音楽、舞踊、劇 自己表現（創造性、感情、自己の表現） 絵画、詞 精神的・宗教的探求（哲学的、宗教的、霊的な探求） 礼拝、哲学的な対話 感情的反応 感動的な劇、映画、音楽 探究心の刺激 探検旅行、科学実験 コミュニケーション（アイデア、感情、情報の伝達） ニュース番組、ブログ、ソーシャルメディア 挑戦と成長（スキル、知識の促進） チェス、パズルゲーム、自己啓発書 基本的な目的のカテゴリーは時代を通じて一貫している
楽しさの源 楽しさを感じる過程 外部刺激の受容 人間の五感（視覚、聴覚、臭覚、味覚、触覚） 環境的要素（置かれている状況） 感覚情報の処理 脳の反応（五感情報が脳内の特定の領域で処理される） 生物学的・神経科学的要素（脳内の化学物質（ドーパミンなど）の影響） 感情の解釈と経験の形成 心理学的要素（過去の経験、期待、文化的背景による影響） 個人的・心理的要素（性格や感情調整能力による影響） 社会的・文化的影響 社会文化的要素（共感や共有される経験など） 感情の表出と共有 感情の共有（他人からの新しいフィードバックの影響） これらの過程が連続的に影響し合いながら、楽しさという複合的な感情体験が形成される
感情 感情体験の例 喜び（基本感情） 幸福感、満足感、興奮 悲しみ（基本感情） 哀しみ、落胆、絶望 怒り（基本感情） 憤り、イライラ、憎悪 恐怖（基本感情） 不安、驚き、パニック 嫌悪（基本感情） 嫌悪感、反発、嫌気 驚き（基本感情） 驚愕、仰天、意外さ 愛情（複合感情） 愛、親近感、同情 罪悪感（複合感情） 後悔、罪悪感、恥 羨望（複合感情） 羨望、嫉妬、欲望 感謝（複合感情） 感謝、謝意、感動 プライド（複合感情） 自尊心、誇り、自身 共感（社会的感情） 共感、理解、共有 孤独感（社会的感情） 孤独、孤独感、疎外感 所属感（社会的感情） 帰属意識、安心感 競争心（社会的感情） 欲求、緊張感 成功の喜び（状況依存の感情） 達成感、満足感 失敗の悲しみ（状況依存の感情） 落胆、失望 解放感（状況依存の感情） 解放感 肯定的感情（肯定的・否定的感情） 喜び、感謝、愛情 否定的感情（肯定的・否定的感情） 悲しみ、怒り、恐怖 面白いエンタメコンテンツは魅力的な感情体験によって提供され、魅力的な感情体験を生み出すには感情体験の量とバランスが適切でなければならない</description>
    </item>
    
    <item>
      <title>GameDev #5 OpenGL [Devlog #019]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_gl_05/</link>
      <pubDate>Tue, 12 Dec 2023 23:58:09 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_gl_05/</guid>
      <description>ゲーム開発者の教科書：Game Programming in C++ を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
ゲームプログラミング in C++ OpenGL ここでは、GameDev #3 ベクトルと物理法則 [Devlog #016]で作成したゲームプロジェクトの描画をOpenGLで書き換える（SDLのレンダラーは2Dグラフィックスのみをサポート）
OpenGLを初期化する 30年以上も使われているOpenGLは、2D/3Dグラフィックスのためのクロスプラットフォームな業界標準ライブラリである
ここではOpenGL 3.3までに定義された関数を使う
以下では、OpenGLとGLEW（ヘルパーライブラリ）の設定と初期化のステップを説明する
OpenGLウィンドウの設定 OpenGL コンテクストと、GLEWの初期化 フレームのレンダリング 三角形の基礎 なぜポリゴンなのか 正規化デバイス座標系（NDC） 頂点バッファとインデックスバッファ シェーダー 頂点シェーダー フラグメントシェーダー 基礎的なシェーダーを書く シェーダーを読み込む 三角形を描画する 座標変換の基礎 オブジェクト空間 ワールド空間 ワールド空間への座標変換 行列と変換 行列の乗算 行列で座標を変換する ワールド空間への座標変換（再び） Actorにワールド変換を加える ワールド空間からクリップ空間への変換 変換行列を使うようにシェーダーを更新する テクスチャマッピング テクスチャをロードする 頂点フォーマットを更新する シェーダーを更新する アルファブレンディング ゲームプロジェクト まとめ </description>
    </item>
    
    <item>
      <title>CG×ML #4 Neural Radiance Fields [Devlog #018]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg-ml_04/</link>
      <pubDate>Sun, 26 Nov 2023 00:34:48 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg-ml_04/</guid>
      <description>NeRF(Neural Radiance Fields) ボリュームベースのレンダリング レンダリング方式 メッシュベース ラスタライゼーション 3Dモデルのポリゴン（通常は三角形）を個々に処理する
ポリゴンはカメラ（ビューポート）に基づいて2D画面に投影される
投影されたポリゴンは、スクリーン上のピクセルにマッピングされる（ポリゴンの各頂点の色、テクスチャ座標、その他の属性が考慮される）
ピクセルに色を割り当てるために、シェーディングアルゴリズム（例えばフォンシェーディング）が用いられる
レイトレーシング 視点（カメラ）からシーン内の各ピクセルに向けて光線（レイ）を発射する
これらの光線がシーン内のオブジェクト（ポリゴンメッシュ）と交差するかどうかを計算する
光線がオブジェクトに当たると、反射、屈折、影など、光のさまざまな物理的挙動を計算する
最終的なピクセルの色と明るさは、交差したポイントでの光の挙動と物質の特性に基づいて計算する
参考：レイトレーシングとラスタライズの違い - NVIDIA
ボリュームベース 直接ボリュームレンダリング（Direct Volume Rendering, DVR） ボリュームデータセット全体が直接画像に変換される
透過率や色をデータ値に基づいて割り当て、複数の値を積み重ねて最終的な画像を生成する
医療画像（CTやMRIスキャンなど）の3D可視化に広く用いられる
レイキャスティング（Ray Casting） ビューワーからボリュームデータを通してレイ（光線）を投射し、その経路上のデータをサンプリングして画像を生成する
高品質な画像を生成することができますが、計算コストが高い
スプラットティング（Splatting） ボリュームデータセット内の各データポイントから画像平面上に「スプラット」と呼ばれる影響領域を投影する方法
テクスチャベースボリュームレンダリング ボリュームデータを視覚化するために3Dテクスチャマッピング技術を利用する手法
3D空間内で定義された一連の平面（または他の形状）をボリュームデータを通過するように配置して、各平面はテクスチャから対応するデータスライスをサンプリングする
ISOサーフェスレンダリング ボリュームデータ内で特定の値を持つ表面（ISOサーフェス）を抽出し、その表面のみをレンダリングする
抽出されたサーフェスは通常、「マーチングキューブス」アルゴリズムなどの手法を用いてポリゴンメッシュ（多くの場合は三角形のメッシュ）に変換される
マルチモーダルレンダリング 異なる種類のデータソース（例えば、CTとMRIデータ）を組み合わせて、1つの統合された画像を生成する
各モダリティのデータの長所を組み合わせることで、より包括的な可視化が可能
Structure from Motion（SfM）によるカメラ姿勢推定 SfMは複数の2D画像から3D空間内のカメラの動き（姿勢）とシーンの構造を同時に推定する
特徴点の抽出とマッチング 複数の画像から特徴点（キーポイント）を抽出し、異なる画像間でこれらの点をマッチングする
カメラ姿勢の推定 画像間の特徴点の対応関係から、各画像に対応するカメラの姿勢（位置と方向）を推定する
SfMではその他にも、3Dポイントクラウドの生成や最適化と精度向上を行う MVSとの連携によるフォトグラメトリ（参考） マルチビューステレオ（Multi-View Stereo, MVS）は、SfMで得られたカメラ姿勢情報を基に、複数の画像からより詳細な3Dシーンを再構築する技術である
具体的には、複数の画像間でピクセルの一貫性を検証し、精密な3Dモデルを作成する
得られた高密度ポイントクラウドから、滑らかなサーフェスモデルを作成できる
これらSfMとMVSを連携して使用することがフォトグラメトリでは一般的となっている
ライトフィールドとライトフィールドフォトグラフィー ディープラーニングとニューラルネットワーク ニューラルネットワークとは，人間の脳内にある神経細胞（ニューロン）との接続関係を数理モデル化したネットワークを意味する（人口ニューラルネットワーク - artificial neural network）
基本的には関数の補間問題として捉え，$k$次元の変数を引数とする未知の関数$f(\bm{x})$に対して，離散的なサンプル点$\bm{x}=\bm{x_p}(p=1, 2, &amp;hellip; ,N)$での値$f_p:=f(\bm{x_p})$は既知であるとし，$\bm{x}\neq \bm{x_p}$に対する$f(\bm{x})$の値を求める問題を考える</description>
    </item>
    
    <item>
      <title>GameDev #4 人工知能 [Devlog #017]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_gl_04/</link>
      <pubDate>Fri, 17 Nov 2023 23:52:09 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_gl_04/</guid>
      <description>ゲーム開発者の教科書：Game Programming in C++ を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
ゲームプログラミング in C++ 人工知能（AI） ゲームでの人工知能アルゴリズムは、コンピュータが制御するエンティティ（entity）の行動を決めるのに使われる
ここでは、ステートマシンによる振る舞い、エンティティが移動する経路を計算する経路探索（pathfinding）、2人が交換でプレイするターン制の対戦ゲームでの思考に使うゲーム木やミニマックス法を使った&amp;quot;タワーディフェンス&amp;quot;型のゲームについて考える
ステートマシンの振る舞い 以下は実装内容である
それぞれの状態の実装を別々の派生クラスに入れることで、状態のカプセル化を単純にでき、別のAIキャラクターで状態を簡単に再利用することができる
ステートマシンを設計する 状態そのものは、ステートマシンを部分的にしか定義しない
状態の変化を決定する状態間の遷移も重要であり、状態に入る時や出る時に発生するアクションがあることがある
ステルスゲームの護衛キャラを考えるとわかりやすい
基本的なステートマシンの実装 AIComponent.h 状態の振る舞いをカプセル化する
AIComponent.cpp AIComponent::Update() ステルスゲームの護衛キャラの場合（P96図4.1）、それぞれの状態に1個ずつの更新関数、UpdatePatrol、UpdateDeath、UpdateAttackを用意する
AIStateクラスのメンバ関数で現在の状態を判定し、個々の状態に対する更新関数を呼び出す
クラスとしての状態 AIState.h 状態を個別のクラスで表現する
この基底クラスには、状態を制御する仮想関数が含まれており、状態を更新するUpdate()、遷移に入る際の処理OnEnter()、遷移から出る際の処理OnExit()を実装する
メンバ変数mOwnerを通して、AIComponentがAIStateに関連つけられる
AIComponent.h コンストラクタAIComponent()と、状態を判定して更新関数を呼び出すUpdate()、ステートマシンの遷移を処理するChangeState()を宣言する
連想配列std::unorderd_map&amp;lt;std::string, class AIState*&amp;gt; mStateMapと、現時点のAIStateへのポインタmCurrentStateを持つ
RegisterState()は新たな状態を連想配列に登録する
AIComponent.cpp AIComponent::Update() 現在の状態があれば、そのUpdate()を呼び出す
if (mCurrentState){ mCurrentState-&amp;gt;Update(deltatime); } AIComponent::ChangeState() 現在の状態のOnExit()を呼び出し、変更先となる状態を連想配列で探す
新たな状態が見つかれば、mCurrentStateをその状態に変更して、新しい状態のOnEnterを呼び出す
if (mCurrentState) { mCurrentState-&amp;gt;OnExit(); } auto iter = mStateMap.find(name); if (iter != mStateMap.end()) { mCurrentState = iter-&amp;gt;second; mCurrentState-&amp;gt;OnEnter(); } else { SDL_Log(&amp;#34;Could not find AIState %s in state map&amp;#34;, name.</description>
    </item>
    
    <item>
      <title>OpenCVについてのメモ [Memo #004]</title>
      <link>https://nishihi6.github.io/blog/posts/memo_opencv_01/</link>
      <pubDate>Thu, 09 Nov 2023 20:57:20 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/memo_opencv_01/</guid>
      <description>画像処理にはよくOpenCVが利用される
OpenCVとは OpenCV（Open Source Computer Vision Library） オープンソースのコンピュータビジョンと機械学習のソフトウェアライブラリ
リアルタイムの画像処理に使用される
画像処理と解析：画像のフィルタリング、変形、オブジェクトの検出などの基本的な機能
顔認識とオブジェクト識別：顔の検出、物体の識別や追跡など
マシンビジョンアプリケーション：3Dモデルの構築、ステレオビジョンを用いた奥行き知覚、モーショントラッキング
機械学習：k-最近傍アルゴリズム、サポートベクターマシン、人工ニューラルネットワークなどのアルゴリズムをサポート
ビデオ分析：ビデオのキャプチャ、ビデオファイルからのフレームの抽出、背景差分法など
OpenCVをVisual Studio2022で利用する 以下のサイトを参考にOpenCVをダウンロード＆インストールし、Visual Studio2022のプロジェクトを設定する
https://qiita.com/h-adachi/items/aad3401b8900438b2acd
簡単な2値化処理 #include &amp;lt;iostream&amp;gt; #include &amp;lt;opencv2/opencv.hpp&amp;gt; int main(int argc, char** argv) { // 引数チェック if(argc != 3) { std::cout &amp;lt;&amp;lt; &amp;#34;Usage: &amp;#34; &amp;lt;&amp;lt; argv[0] &amp;lt;&amp;lt; &amp;#34; &amp;lt;input_image_path&amp;gt; &amp;lt;output_directory&amp;gt;&amp;#34; &amp;lt;&amp;lt; std::endl; return -1; } // 画像をカラーで読み込む cv::Mat src = cv::imread(argv[1], cv::IMREAD_COLOR); if(src.empty()) { std::cerr &amp;lt;&amp;lt; &amp;#34;Error: Could not open or find the image!&amp;#34; &amp;lt;&amp;lt; std::endl; return -1; } // グレースケール変換 cv::Mat gray(src.</description>
    </item>
    
    <item>
      <title>GameDev #3 ベクトルと物理法則 [Devlog #016]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_gl_03/</link>
      <pubDate>Sat, 04 Nov 2023 15:14:20 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_gl_03/</guid>
      <description>ゲーム開発者の教科書：Game Programming in C++ を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
ゲームプログラミング in C++ ベクトルと物理法則 ベクトル オブジェクトの前方ベクトルは、オブジェクトの進む方向を表現するベクトルである
このコードではMath.hヘッダファイルに含まれる独自のベクトルライブラリを使う
Vector2 myVector; myVector.x = 5; myVector.y = 10; 2点間のベクトルを作る（減算） Vector2 a, b; Vector2 result = a - b; ベクトルのスケーリング（スカラ乗算） Vector2 a; Vector2 result = 5.0f * a; ベクトルを組み合わせる（加算） Vector2 a, b; Vector2 result = a + b; 距離を求める（長さ） ベクトルは大きさと向きの両方を表現する
平方根の処理はCPU処理において多くのクロック数を必要とするため、大小の比較だけの場合はベクトルの長さの2乗を比較するべきである
ベクトルの長さと長さの2乗は以下のように求める
Vector2 a; float length = a.Length(); float length_squared = a.LengthSquared(); 向きを求める（単位ベクトルと正規化） 単位ベクトルは、長さが1のベクトルである
非単位長のベクトルから単位ベクトルへの変換を正規化という
ゼロ除算を考慮する必要があるほか、ベクトルを正規化すれば大きさの情報は失われるため、タイミングを考慮する必要がある
正規化は前方ベクトルや上向きベクトルに対して用いられる
Math.h 指定されたベクトルをその場で正規化するNormalize()関数と、引数として渡されたベクトルを正規化してその正規化されたベクトルを変えるNormalize()静的関数がある</description>
    </item>
    
    <item>
      <title>GameDev #2 ゲームオブジェクトと2Dグラフィクス [Devlog #015]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_gl_02/</link>
      <pubDate>Mon, 30 Oct 2023 23:03:24 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_gl_02/</guid>
      <description>ゲーム開発者の教科書：Game Programming in C++ を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
ゲームプログラミング in C++ ゲームオブジェクトと2Dグラフィクス ゲームオブジェクト オブジェクト階層構造を利用するゲームもあれば、コンポジションを使うゲームもあり、もっと複雑な手法を用いるゲームもある
ゲームオブジェクトの種類 ゲームオブジェクトには、毎フレーム更新されて出力生成で描画されるもの、描画するが更新しない静的オブジェクト、他のオブジェクトが触れた際に何かを発生させるトリガーなどがある
ゲームオブジェクトのモデル ●クラス階層構造としてのゲームオブジェクト
オブジェクト志向の標準的なクラス階層構造でゲームオブジェクトを宣言するゲームオブジェクトモデル（is-a関係）
すべてのゲームオブジェクトが1つの基底クラスから派生されるので、モノリシックなクラス階層構造とも呼ばれる
どのゲームオブジェクトも基底オブジェクトのプロパティと関数をすべて持たなければならないという欠点がある
階層構造を拡張して、派生クラス群と基底クラスとの中間に新しいクラスを置くこともできるが、クラス階層構造が複雑化してしまう
クラス階層構造を大きくすると、後に2つの子クラスに共通機能をもたせようとした際に、2つの別の経路で継承することになり（菱形継承）、派生クラスが仮想関数の複数のバージョンを継承する問題を起こしやすい
●コンポーネントによるゲームオブジェクト
コンポーネント（構成要素）をベースとするゲームオブジェクトモデル
Unityが採用しているモデルである
1つのゲームオブジェクトクラスがあるが派生クラスを持たず、代わりに必要な機能を実装するコンポーネントオブジェクトを持つ（has-a関係）
このモデルを実装する方法の1つは、コンポーネントにクラス階層構造を使う手法
GameObjectに含まれるのは、コンポーネントを追加（Add）・削除（Remove）する関数だけである
必要とする機能だけを追加しやすいという長所がある
同じゲームオブジェクトにあるコンポーネント間の依存関係が明らかではないという欠点がある
●階層構造とコンポーネントによるゲームオブジェクト
モノリシックな階層構造とコンポーネントオブジェクトモデルのハイブリッド
UE4のゲームオブジェクトモデルから部分的にヒントを得ている
Actor.h Actor.cpp いくつかの仮想関数を持つ基底クラスActorがあり、各基底クラスActorはコンポーネントを格納する動的配列（std::vector）を持つ
列挙型のStateでクラスActorの状態管理を行う（Update()はEActive状態のクラスだけを更新し、EDead状態のクラスは削除する）
UpdateComponents()関数は、すべてのコンポーネントをループして順番に更新する
UpdateActor()関数は、派生クラスで独自の振る舞いを実装する
基底クラスActorでは、アクターを追加で作成する際にGameクラスへのアクセスが必要になり、シングルトンで実装するアプローチ（そのクラスの複数のインスタンスに対応できない）もあるのだが、依存性の注入（dependency injection）で実装する（アクターがコンストラクタでGameクラスへのポインタを受け取り、別のアクターを追加作成する）
Component.h Component.cpp メンバ変数mUpdateOrderはコンポーネントの更新順を前後させる（例えば、カメラコンポーネントは移動コンポーネントがプレイヤーを動かした後に更新する）
処理順を管理するため、ActorのAddComponent()関数では新しいコンポーネントが追加される際にコンポーネントの配列をソートする
Componentクラスは、その所有者のアクターへのポイントを持つことで、コンポーネントからアクターの情報にアクセスできる
このハイブリッドアプローチは、モノリシックなオブジェクトモデルの&amp;quot;深いクラス階層構造&amp;quot;を避けるという点で有効である
座標データなどの重要なプロパティを個々のアクターにもたせているため、コンポーネント間のオーバーヘッドに関する問題を回避することができる
●その他のアプローチ
考えられるさまざまな機能をインターフェースクラスとして宣言し、個々のゲームオブジェクトで必要なインターフェースを実装する
コンテナ的なゲームオブジェクトを完全に排除し、代わりにIDでオブジェクトを管理するコンポーネントのデータベースを利用する
オブジェクトをプロパティによって定義する
ゲームオブジェクトをゲームループに統合する Game.h Actorクラスへのポインタの、アクティブなアクター群を含むmActorsと待ち状態のアクター群を含むmPendingActors（std::vector）をGameクラスに追加
新しいアクターは巡回処理が終わるまではmPendingActorsに追加しておく
Game.cpp 受け取ったActorクラスへのポインタを、mUpdatingActorsフラグによってmPendingActorsかmActorsに追加するGame::AddActor()関数を追加
Actorクラスへのポインタを受け取って、そのアクターを削除するGame::RemoveActor()関数を追加する
Game::UpdateGame() デルタタイムの計算後にmActorsにあるアクターをループ処理して、それぞれのActor::Update()を呼び出す
mPendingActorsに追加したアクターをmActorsに移動する
死んだアクターをdeadActorsに移動して削除する
Game::UnloadData() Actorオブジェクトはコンストラクタとデストラクタで自動的に追加・削除されるため、mActosrをループ処理してアクターを削除するには別のスタイルのループを行う
スプライト 2Dゲームの視覚的オブジェクトのスプライトは、キャラクター、背景、その他の動的なオブジェクトを表現するのに使われる
それぞれのスプライトには、1つ以上の画像ファイルが割り当てられる
iOSではPVR、PC及びXBoxではDXTなどの画像フォーマットを利用する
このコードではPNGを利用する（PNGは圧縮された画像フォーマットであり、ハードウェアはPNGファイルをネイティブで描画できないため時間が掛かるが…）
画像ファイルのロード Game.cpp Game::Initialize() SDL_Init()関数でSDL Imageを初期化する</description>
    </item>
    
    <item>
      <title>GameDev #1 ゲームプログラミング [Devlog #014]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_gl_01/</link>
      <pubDate>Thu, 26 Oct 2023 18:53:04 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_gl_01/</guid>
      <description>ゲーム開発者の教科書：Game Programming in C++ を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
ゲームプログラミング in C++ 環境構築 VisualStudio2022でプロジェクトの作成 (新規作成-&amp;gt;プロジェクト-&amp;gt;)新しいプロジェクトの作成-&amp;gt;空のプロジェクト プロジェクト名（ソリューション名）と保存パスを指定 &amp;ldquo;ソリューションとプロジェクトを同じディレクトリに配置する&amp;quot;にチェック 作成 SDL等のライブラリを設置（$(SolutionDir)\External\フォルダ以下） ソリューションのプロパティを変更（参考サイト） インクルードディレクトリの指定 構成プロパティ-&amp;gt;C/C++-&amp;gt;全般-&amp;gt;追加のインクルードディレクトリ（注意点） 追加のライブラリディレクトリの指定 構成プロパティ-&amp;gt;リンカー-&amp;gt;全般-&amp;gt;追加のインクルードディレクトリ 追加の依存ファイルの指定 構成プロパティ-&amp;gt;リンカー-&amp;gt;入力-&amp;gt;追加の依存ファイル DLLをビルド時にコピー 構成プロパティ-&amp;gt;ビルドイベント-&amp;gt;ビルド後のイベント-&amp;gt;コマンドライン ※サンプルソースコードではプラットフォームをWin32に設定しているので注意
ゲームプログラミング ゲームループとゲームクラス ゲームループ（game loop）は、ゲームプログラム全体の流れを制御するループである
シングルスレッドのゲームループに対して、マルチスレッドのゲームループは複雑になる
フレームの中身 ゲームは各フレームで次の3つのステップを実行する
入力があれば処理する 例：デバイス入力、インターネット経由で受信したデータ、カメラ映像、GPS情報 ゲームワールドを更新する 例：キャラクター、ユーザインターフェースのパーツ、ゲームに与える全ての要素 出力するものを生成する 例：グラフィクス、オーディオ、フォースフィードバック（振動）、インターネット経由で送信するデータ ゲームクラスの骨組みを実装する Game.h Gameクラス Initialize()関数はGameクラスを初期化する
RunLoop()関数はゲームループを実行する
Shutdown()関数はゲームを終わらせる
ProcessInput()関数、UpdateGame()関数、GenerateOutput()関数はゲームループの3つのステップに対応する
mIsRunningは、ゲームループを続行するか否かを示すフラグ
Game.cpp Game::Initialize() SDL_Init()関数は、SDLライブラリを初期化する
今のところ、初期化する必要があるのはビデオサブシステムだけ（SDL_INIT_VIDEO）
SDL_Log(&amp;quot;Unable to initialize SDL: %s&amp;quot;, SDL_GetError())は、SDLでメッセージをコンソールに出力する簡単な方法である
SDL_GetError()関数は、エラーメッセージを文字列で返す
SDL_CreateWindow()関数でウィンドウを作る
ウィンドウ作成にはフラグを設定できる（SDL_WINDOW_FULLSCREENでフルスクリーンモードを使う）
Game::RunLoop() もしmIsRunningがfalseになったら繰り返しをやめる
Game::Shutdown() SDL_DestroyWindow()関数を使ってSDL_Windowを破棄する
SDL_Quit()でSDLを終わらせる
メイン関数 main.cpp どんなC++プログラムでも入り口はmain関数である
最初にGameクラスのインスタンスを作る
ゲームを初期化（game.Initialize()）出来たら、game.RunLoop()を呼び出してゲームループに入る
ループが終わったらgame.Shutdown()を呼び出してゲームを終わらせる</description>
    </item>
    
    <item>
      <title>CG×ML #3 DRを可能にするMitsuba3の中身 [Devlog #013]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg-ml_03/</link>
      <pubDate>Sat, 14 Oct 2023 23:00:08 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg-ml_03/</guid>
      <description>微分可能レンダリングを行うMitsuba3の仕組み Dr.Jit（ジャストインタイムコンパイラ） ここでは微分可能なレンダリングのためのジャストインタイムコンパイラについての論文1を理解する
Wenzel Jakob, Sébastien Speierer, Nicolas Roussel, and Delio Vicini. 2022. Dr.Jit: A Just-In-Time Compiler for Differentiable Rendering. In Transactions on Graphics (Proceedings of SIGGRAPH) 41(4).
Dr.Jitとは 物理ベース微分可能レンダリング（PBDR）のためのジャストインタイムコンパイラ
レンダリングアルゴリズムを実行するとグラフを生成
グラフとは 算術、ループ、レイトレーシングの操作、およびレンダリングアルゴリズムとシーンオブジェクト（形状、BSDF、テクスチャ、エミッターなど）間の情報を交換する多態的な呼び出し（例えば、BRDFのspecularの値を勾配方向に変えながらレイトレーシング操作を繰り返す）
Dr.Jitは提供されるシーンにグラフを特化させ、LLVMまたはOptiXを介してデータ並列カーネル（megakernel）にコンパイルする
通常のレンダリングのほか、微分シミュレーション（differential simulations）を動的にコンパイルする
大きな微分タスクを一連の漸近的なステップに分解するため、自動微分（automatic differentiation）の細かい実行をサポート
画像空間における摂動（perturbation）を計算してデバッグやvisualizationに利用するForwardモードと、たくさんの未知数を同次最適化するためのパラメータ空間の導関数を提供するReverseモードを実装している
パラメータ空間の例 シーン上での壁紙のテクセル（テクスチャ空間の基本単位）
目的 Python等の高レベル言語で記述されたシミュレーションコードの実行を追跡し、どの部分のコードがどのように動作しているのか、どの部分が計算負荷が高いのかなどの情報をもとに、コードを効率的に最適化・変換し、高速なデータ並列カーネルを生成する
微分の過程をより効率的に、かつ細かい制御のもとで行うことをサポートし、微分可能なレンダリングアルゴリズムの開発を簡易化する（効率的な方法としてシミュレーションの微分を微分のシミュレーションに変える）
&#34;シミュレーションの微分を微分のシミュレーションに変える&#34;とは Derivative of a simulation（シミュレーションの微分）：
シミュレーションが入力に対してどのように変化するかを示す
例えば、物理ベースのレンダリングの場合、光の強度や物質の性質などの入力パラメータに微小な変化を加えたときの出力画像の変化量がこれに該当する
Simulation of the derivative（微分のシミュレーション）：
微分そのものを新しいシミュレーションとして扱う考え方
つまり、入力の変化に対する出力の変化を直接シミュレートすることで、微分の効果を視覚化や解析するためのツールとして利用する
この変換はMitsubaにおいて重要。なぜなら、 多くのアルゴリズムや最適化手法は、微分の情報を使用して動作する
微分可能なレンダリングは、シーンのパラメータを最適化するための勾配情報を提供する能力が求められる
この勾配情報は、シーンの照明や材料の性質、カメラの位置などのパラメータを調整して、目的の画像や効果に近づけるために使用される
Dr.Jitは自動微分のプロセスを細かく制御してこの変換を支援する また、Dr.Jitはデータの依存関係をグローバルに追跡し、最終的に勾配に影響を与えない計算（冗長なシミュレーション）を削除することで効率を上げる
Introduction 物理ベースの微分可能レンダリング（PBDR） PBDRは、任意のシーンパラメータに基づいて光輸送シミュレーションを微分できる
勾配ベースの最適化と組み合わせ、多くの未知数を持つ非線形の問題を解決する
この技術は、画像の逆解析が必要な多くの分野での利用が期待される
PBDRの課題 実用的な実装が難しい</description>
    </item>
    
    <item>
      <title>量子情報工学メモ #1 量子力学 [Memo #003]</title>
      <link>https://nishihi6.github.io/blog/posts/memo_qm_01/</link>
      <pubDate>Thu, 12 Oct 2023 19:45:54 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/memo_qm_01/</guid>
      <description>量子コンピューティングを学ぶ 我々が目指している未来を少しでも理解できるようになることが、今後の自らの興味やスキルを発展させていくことで重要と考えたため、量子情報について学びます（CV・CGとは現状関わりの薄い分野ですが…）
背景 2050年頃（自分の子供が社会で活躍し始める頃）には、従来の情報通信技術に量子インターネットや量子センサなどの量子技術が加わり、量子コンピュータを自由自在に組み合わせて使いこなす「量子前提社会」が到来すると考えられている1
情報化社会が到来し、インターネットやコンピュータが多くの社会課題を解決してきたが、これの延長線上にあるものとして、量子情報技術はより難しい課題を解決すると考えられる
量子前提社会で必要とされる誤り耐性量子コンピュータの大規模化の実装は、操作精度や実装精度などに何万倍もの向上が必要になるが、原理的に実現を妨げる障壁は無い
また、大規模化を達成した誤り耐性量子コンピュータの実現は、内閣府が2020年に設定したムーンショット計画でも目標とされている2
※誤り耐性型汎用量子コンピュータ 大規模な集積化を実現しつつ、様々な用途に応用する上で十分な精度を保証できる量子コンピュータ ※ムーンショット計画 従来技術の延長を担い、より大胆な発想に基づく挑戦的な研究開発の推進を目的とした計画（名前の由来はケネディ大統領のアポロ計画に関する演説で用いられた言葉からきている） 関連動画 量子力学（Quantum Mechanics） システムと実験 - Systems and Experiments Quantum Mechanics Is Different Spins and Qubits An Experiment Experiments Are Never Gentle Proposition 古典的な命題のテスト - Testing Classical Propositions 量子的な命題のテスト - Testing Quantum Proposition Mathematical Interlude: Complex Number Mathematical Interlude: Vector Spaces 公理 - Axioms 関数と列ベクトル - Functions and Column Vectors ブラとケット - Bras and Kets 内積 - Inner Products 正規直交基底 - Orthonormal Bases 量子状態 - Quantumn States 状態とベクトル - States and Vectors スピン状態の表現 - Representing Spin States Along the x Axis Along the y Axis パラメータのカウント - Counting Parameters スピン状態を列ベクトルとして表現 - Representing Spin States as Column Vectors これまでのまとめ - Putting It All Together 量子力学の原理 - Principles of Quantum Mechanics 数学上の補説：線形演算子 - Mathematical Interlude: Liner Operators 機会と行列 - Machines and Matrices 固有値と固有ベクトル - Eigenvalues and EigenVectors エルミート共役 - Hermitian Conjugation エルミート演算子 - Hermitian Operators エルミート演算子と正規直交基底 - Hermitian Operators and Orthonormal Bases グラム・シュミット法 - The Gram-Schmidt Procedure 原理 - The Principles スピン演算子 - An Example: Spin Operator スピン演算子の構成 - Constructing Spin Operators よくある誤解 - A Common Misconception 3-ベクトル演算子の再考 - 3-Vector Operators Revisited 計算を行って結果を得る - Reaping the Results スピン偏極の原理 - The Spin-Polarization Principle 時間と変化 - Time and Change 古典力学の考え方 - A Classical Reminder ユニタリー - Unitarity 時間発展演算子</description>
    </item>
    
    <item>
      <title>DirectX12の描画処理 #5 [Devlog #012]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_dx12_05/</link>
      <pubDate>Wed, 11 Oct 2023 23:55:00 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_dx12_05/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CG×ML #2 勾配ベースの最適化（Mitsuba3） [Devlog #011]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg-ml_02/</link>
      <pubDate>Sat, 07 Oct 2023 15:36:49 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg-ml_02/</guid>
      <description>勾配ベースの最適化（Mitsuba3） Mitsuba3の動作確認 Mitsuba3はPyPIからpip経由でインストールすることが推奨されている 公式ドキュメントはこちら
Mitsuba3の使い方（Python） インポート import mitsuba as mi バリアントの選択 バリアントについての詳細
mi.variants() [&#39;scalar_rgb&#39;, &#39;scalar_spectral&#39;, &#39;cuda_ad_rgb&#39;, &#39;llvm_ad_rgb&#39;] この4つ以外のバリアントを必要とする場合は、pipではなく自力でコンパイルする必要がある（ソースからのコンパイルに関するドキュメントはこちら）
mi.set_variant(&amp;#34;scalar_rgb&amp;#34;) 計算バックエンド（Computational backend）の指定 scalar：旧Mitsubaと同様にCPU上で浮動小数点演算を実行する（一度に個々のレイを処理するモードであるため、コンパイルエラーの修正やレンダラーのデバッグに適している）
cuda：Dr.JITが計算をCUDAカーネルに変換してGPUにオフロードする（GPUレイトレーシングにNVIDIAのOptiXライブラリを使用する）
llvm：Dr.JITが計算を並列CPUカーネルにコンパイルする（LLVMコンパイラフレームワークを使用する）（※ NVIDIA GPUを持っていない場合の代替手段）
自動微分（Automatic differentiation）の指定 _ad：自動微分を有効にする（cudaとllvmモードで指定可能）
主に微分可能レンダリングを行う際に利用するモードで、光の動きを含めた複雑な逆問題を解く
色の表現（Color representation）の指定 mono：単色ベースの色表現
rgb：RGBベースの色表現
spectral：可視域をカバーする完全なスペクトルカラー表現
偏光（Polarization）の指定 偏光の追跡が必要な場合に指定する追加オプション
偏光は逆問題を解決するための強力なツールである
精度（Precision）の指定 _double：通常の演算で設定している単精度（32bit）から倍精度（64bit）に設定を変更する（EmbreeとOptiXが倍精度をサポートしていないことを考慮した設定が必要な場合がある）
シーンのロード scene = mi.load_file(&amp;#34;../scenes/cbox.xml&amp;#34;) Mitsuba3ではシーンの記述にXMLベースの形式を利用する（シーンXMLファイルフォーマットに関するドキュメントはこちら）
シーンのレンダリング image = mi.render(scene, spp=256) render()関数を使用してシーンをレンダリング
render()は線形RGB色空間テンソル（NumPy配列に似たmi.TensorXf）を返す
（APIリファレンスはこちら ※サイトが重いので注意）
mi.Bitmap(image) レンダリング画像の表示
matplotlibを使っても画像を表示できる import matplotlib.pyplot as plt plt.axis(&amp;#34;off&amp;#34;) plt.imshow(image ** (1.0 / 2.2)); レンダリング画像の保存 mi.util.write_bitmap(&amp;#34;my_first_render.png&amp;#34;, image) mi.</description>
    </item>
    
    <item>
      <title>CG×ML #1 微分可能レンダリング [Devlog #010]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg-ml_01/</link>
      <pubDate>Wed, 04 Oct 2023 16:03:45 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg-ml_01/</guid>
      <description>微分可能レンダリング（differential rendering） 微分可能レンダリングとは 微分可能レンダリングは、コンピュータグラフィックスと機械学習を組み合わせた技術であり、2D画像から3D空間のパラメータを推定することを目的としている
通常のレンダリングでは、3Dモデル、カメラ位置、ライティング条件などのパラメータを利用して2D画像を生成するが、微分可能レンダリングはこのレンダリングのプロセスを逆に行う
2D画像から3D情報への変換の精度を向上させるために、レンダリング画像と入力画像（教師データ）との差分を計算し、ネットワーク全体を学習する手法として使用される この場合、教師画像データはカメラパラメータ（撮影された位置と方向）がわかっているものとし、レンダリングの際にはそのパラメータと同じような仮想カメラを設定してレンダリング画像を生成することになる
特に3次元形状の教師データが手に入らない場合に効果的で、さまざまな物体カテゴリにも適応可能である
一方で、3Dデータ（3次元形状やポーズなど）を機械学習タスクの教師データとして用いる学習は&amp;quot;3D supervision&amp;quot;と呼ばれる こちらは3D教師データを大量に用意しなければならないという点であまり現実的な選択肢ではない
微分可能レンダラとは レンダリング画像における入力画像（教師データ）との差分を誤差逆伝播させてニューラルネットを学習させるには、レンダリング箇所が微分可能である必要がある
つまり、レンダリング画像と入力画像（教師データ）との差分からパラメータの更新ができる（ロスからBackwardできる）レンダラを微分可能レンダラという
勾配ベースの最適化アルゴリズム（SGD、Adam等）で3Dシーンを最適化できるレンダラ
最適化する3Dシーンの例 頂点位置 カメラポーズ（姿勢） テクスチャ ライト その他、レンダリングに関する概念ほぼ全て 参考：微分可能レンダラのつくりかた 参考：ニューラルネット3D表現に対する微分可能レンダラー 参考：微分可能レンダリング
3次元構造の表現方法（研究発展中） ボクセル（Voxel） 点群（Point） メッシュ（Mesh） +α ニューラルネットワーク表現（ニューラル場） +α 点群-&amp;gt;ガウス メッシュ（Mesh） メッシュ表現を用いる場合は、何らかの初期形状を仮定して、それを変形させることで3次元構造の再構成を行う手法が主流である
レンダリング方式（研究発展中） ラスタライズ レイトレーシング +α Radiance Field +α 微分可能ガウスラスタライズ ラスタライズは視界の範囲だけ、レイトレーシングは視界範囲外の考慮してレンダリングする
参考：レイトレーシングとラスタライズの違い - NVIDIA
ラスタライズのアプローチ メッシュの微分可能ラスタライズには2つのアプローチがある
レンダリング画像を変えずに擬似的な勾配を計算（逆伝搬を工夫） レンダリング画像をぼやかすことで最適化に有用な勾配を得る（順伝搬を工夫） レイトレーシングのアプローチ 物理ベース微分可能レンダリング
計算速度が遅く、深層学習（機械学習）と組み合わせるのは難しいのが現状
Neural Radiance Field（NeRF）のアプローチ レンダリング方程式（詳細）を逆問題として解くが、ピクセルの色の決定にボリュームレンダリングを用いる
NeRF（neural radiance field）のボリュームレンダリングは微分可能（特に工夫は必要ない（自動微分でオーケー））
レンダリング方程式を放射輸送方程式に戻し、ニューラルネットワークで表される3Dシーン（ベクトル場）と微分可能なボリュームレンダリング関数で解く
ニューラル場（Neural Fields）の研究はNeRFの登場以前からも行われており、NeRFはDeepSDFのテクニックを継承している
陰関数とCGの関係 従来のCGは離散的な頂点定義によって成り立っているのに対して、陰関数（Implicit Function）によるCGは連続的な数学定義によって成り立っている
陰関数で0の値をとるサーフェスを定義し、距離場（SDF、TSDF、DeepSDF）はそのサーフェスからの距離を定義する
関数でCGが表現できる！（密に点群を用意せずとも関数でCGが表現できる点で最近注目されている）
参考：【メタサーベイ】Neural Fields</description>
    </item>
    
    <item>
      <title>CG理論 #4 シェーディング [Devlog #009]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg_04/</link>
      <pubDate>Sat, 30 Sep 2023 22:43:30 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg_04/</guid>
      <description>CG屋さんのバイブル：Real Time Rendering Fourth Edition を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
シェーディング シェーディングの基礎 シェーディングモデル 光源 平行光源 点光源 ポイント/オムニライト スポットライト その他の点光源 その他のライト シェーディングモデルの実装 評価の頻度 実装例 マテリアルシステム エイリアシングとアンチエイリアシング サンプリングとフィルタリングの理論 再構成 リサンプリング スクリーンベースのアンチエイリアシング サンプリングパターン 形態学的手法 透明度、アルファと合成 ブレンドの順番 順番に依存しない透明度 乗算済みアルファと合成 ディスプレイエンコーディング </description>
    </item>
    
    <item>
      <title>CG理論 #3 変換 [Devlog #008]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg_03/</link>
      <pubDate>Fri, 29 Sep 2023 23:41:38 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg_03/</guid>
      <description>CG屋さんのバイブル：Real Time Rendering Fourth Edition を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
変換 変換（transform） 線形変換はベクトル加算とスカラー乗算を保存するもの $$ \textbf{f}(\textbf{x}) + \textbf{f}(\textbf{y}) = \textbf{f}(\textbf{x}+\textbf{y}) $$ $$ k\textbf{f}(\textbf{x}) = \textbf{f}(k\textbf{x}) $$ これが満たされれば線形であるといえる
スケール変換や回転変換など、3要素ベクトルに対するすべての線形変換は3×3行列で表せる 線形変換は原点を不動点とする変換であり、原点は変換されずにそのままの位置に残る
3要素ベクトル $\textbf{x}$ への写像 $\textbf{f}(\textbf{x}) = \textbf{x} + (7, 3, 2)$ のような平行移動は線形ではない 平行移動は、原点の位置が変わるという特性がある
線形変換と平行移動の結合は、一般に4×4行列で格納されるアフィン変換を使って表す
同次表記は点と方向（ベクトル）を同じ形式で扱うことを可能にする
同次座標系では、 $n$ 次元空間における点を $n+1$ に拡張し、例えば3次元点 $(x,y,z)$ はベクトル $(x,y,z,1)$ と表現する
$$ \textbf{v} = \begin{pmatrix} x &amp;amp; y &amp;amp; z &amp;amp; 1\ \end{pmatrix}^T $$
方向（ベクトル）についても、$n$ 次元空間であれば $n+1$ に拡張し、3次元ベクトル $(v_x,v_y,v_z)$ はベクトル $(v_x,v_y,v_z,0)$ と表現する
$$ \textbf{v} = \begin{pmatrix} v_x &amp;amp; v_y &amp;amp; v_z &amp;amp; 0\ \end{pmatrix}^T $$</description>
    </item>
    
    <item>
      <title>DirectX12の描画処理 #4 [Devlog #007]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_dx12_04/</link>
      <pubDate>Wed, 20 Sep 2023 22:48:58 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_dx12_04/</guid>
      <description>DirectX12を使った描画処理 ポリゴンの描画 ライブラリの導入 DirectXMath DirectXMath APIは、DirextXアプリケーションに共通する一般的な線形代数およびグラフィックス演算用のSIMD対応のC++関数を提供するライブラリで、ユニバーサルWindowsプラットフォームアプリ、Xboxゲーム開発者向けに設計されている 詳細
DirectXTK DirectXTK(DirectX Tool Kit)は、マイクロソフト社が提供するDirectX 11と12に対応したゲーム開発を行うためのオープンソースのクラスライブラリであり、XNA Game Framework（2006年に発表）がC++に移植されたもの DirextXTKの詳細 ユニバーサルWindowsプラットフォーム(UWP)用ゲーム開発の詳細
NuGet NuGetは、Microsoft .NET環境で使用されるパッケージマネージャーであり、拡張子が.nupkgのzipファイルにはコンパイル済みのコード（DLL）、そのコードに関連する他のファイル、パッケージのバージョン番号などの情報が記述されているマニフェストが含まれる 詳細
DirectXMathの導入 Visual Studioのツール-&amp;gt;NuGetパッケージマネージャー-&amp;gt;ソリューションのNuGetパッケージの管理で「directxtk12_uwp」を検索して選択、プロジェクト（frameworkDX12を含む）にチェックしてインストール
stdafx.h // stdafx.h // ~ // // DirectX Took Kit #pragma comment(lib, &amp;#34;DirectXTK12.lib&amp;#34;) #include &amp;lt;SimpleMath.h&amp;gt; // ~ // Utility.h // Utility.h // ~ // namespace Math = DirectX::SimpleMath; メッシュ GraphicsフォルダにMeshフォルダを追加し、Mesh.hとMesh.cppを追加
dev-dx12-202308（プロジェクト名） └─ Source ├─ Application │ ├─ Application.h │ └─ Application.cpp ├─ Graphics │ ├─ Mesh │ │ ├─ Mesh.</description>
    </item>
    
    <item>
      <title>Unity-VR 備忘録 #1 [Devlog #006]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_unity-vr_01/</link>
      <pubDate>Wed, 06 Sep 2023 17:42:09 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_unity-vr_01/</guid>
      <description>動作確認 開発環境 Windows10 Unity2022.3.8f1(LTS) MetaQuest2（QuestLink） 環境設定 プロジェクトの設定 レンダリングパイプライン レンダリングパイプラインにはSRP（スクリプタブルレンダーパイプライン）の中でも汎用性の高いURPを使用 URPの詳細
テンプレート 手動でVR周りの設定をするため、テンプレートはVRではなく3D（URP）を使用
パッケージ InputSystem 1.6.3 XR Interaction Toolkit 2.4.3 XR Plugin Management 4.3.3 プロジェクトセッティング Project Settings-&amp;gt;XR Plug-in ManagementのPlug-in ProvidersのOpen XRにチェックを入れる
Project Settings-&amp;gt;XR Plug-in Management-&amp;gt;OpenXRのInteraction ProfilesにOculus Touch Controller Profileを追加
StarterAssetsの追加 Package Manager-&amp;gt;XR Interaction Toolkit-&amp;gt;SamplesからStarterAssetsをインポート
シーンの設定 SampleSceneのMainCameraはVRで利用しないので消去
HierarchyにXR-&amp;gt;XR Origin(VR)を追加
XR OriginコンポーネントがアタッチされたGameObjectのXR Originに、Packages&amp;gt;XR Interaction Toolkit&amp;gt;Runtime&amp;gt;Inputs&amp;gt;InputActionManager.csをアタッチして、 Action AssetsのElement 0に、Assets&amp;gt;Samples&amp;gt;XR Interaction Toolkit&amp;gt;2.4.3&amp;gt;Starter Assets&amp;gt;XRI Default Input Actions.inputactionsを設定する ※設定されてなければ手動で設定
コントローラーの設定 ~Starter Assets&amp;gt;XRI Default Left ControllerをHierarchyのXR Origin&amp;gt;Camera Offset&amp;gt;Left ControllerのXR Controller(Action-based)コンポーネントにドラッグアンドドロップ</description>
    </item>
    
    <item>
      <title>CG理論 #2 グラフィクス処理 [Devlog #005]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg_02/</link>
      <pubDate>Wed, 30 Aug 2023 03:46:40 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg_02/</guid>
      <description>CG屋さんのバイブル：Real Time Rendering Fourth Edition を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
グラフィクス処理 グラフィクス処理ユニット（GPU） グラフィクスを高速化する歴史は、三角形と重なる各ピクセルの色を補間することから始まった
頂点処理を行う消費者用チップとして1999年に出荷されたGeForce 256が初めてのグラフィクス処理ユニット（GPU）であり、ラスタライズ専用チップと差別化する目的でその言葉が生まれた
GPUは特定のタスクに特化した複雑な固定機能パイプライン処理をもつものから、開発者が独自のアルゴリズムを実装できる柔軟性をもつものへと進化している1
GPUの利点は、狭い範囲の高度に並列化可能なタスクのセットに集中することで、頂点変換やピクセルの色計算の処理を高速化させることにある
カスタムシリコンが行う並列処理の例 z-バッファの実装 テクスチャーイメージ、バッファーへの迅速なアクセス 三角形が重なるピクセルの探索 データ並列アーキテクチャ CPU 複数のプロセッサを持つことがあるが、それぞれがほぼ直列に処理を実行し、レイテンシーを最小化するためにチップの多くがメモリーで占められている
ストール（命令の実行が遅れること）を避けるために、分岐予測や命令並べ替え、レジスタリネーミング、キャッシュプリフェッチなどを行う2
GPU よく似たデータの順序つきセット（例えば頂点やピクセルのセット）を順番に並列処理するストリームプロセッサ
それぞれのプロセッサは書き込み可能なメモリ位置の共有を行わず、可能な限り独立するように設計されているため、それぞれのプロセッサが別のプロセッサの作業の終了を待つことが無い
シングルスレッドの性能ではなく、全スレッドの合計の処理性能（スループット）を重視して最適化したプロセッサであり3、ストール発生箇所（高速なローカルメモリではなく別のリソースへアクセスするテクスチャーアクセスなど）を考慮した仕組みになっている （例えば、テクスチャフェッチ中に次のフラグメントの処理に移るなど）
実行の最適化 GPUは、命令実行ロジックをデータから分離した方式SIMD（単一命令複数データ）を利用することで、ロックステップ（多数のデータ要素を同じ命令に従って処理）する
同じシェーダープログラムによって処理される各フラグメントに対するピクセルシェーダーの呼び出し（スレッド）はワープ/ウェーブフロントと呼ばれるグループに束ねられ、GPUシェーダーコアの実行（シェーダープロセス）にスケジュールされる （例えば、32スレッドを束ねるNVIDIA GPUで2000フラグメントを処理すると、63のワープを割り当てることになる（2000/32=62.5））※本書P28 図3.1を参照
各スレッドは個々のレジスタを持ち、ワープ単位で命令を追跡する
ワープはストールする際に別のスレッドのワープとスワップ（スワップイン/アウト）を行う
他にも実行の最適化に使われる技術はいくつかある4
効率を測る シェーダープログラムの構造、特にスレッドごとに使われるレジスタの数が効率に影響し、各スレッドの処理に必要なレジスタが増えるほど、GPU上に常駐できるスレッド数は減るのでワープも減る（ストールをスワップで軽減できなくなる）
参考論文↓ シェーダーが使うレジスタ数と共有メモリの占有率（常駐するワープの数）への影響5 シェーダーが行う操作の種類による理想的な占有率の変化67
if文とループによる動的分岐は全体的な効率に影響するというスレッド発散問題がある （１つでも別の経路をとるスレッドがあると、ワープは両方の分岐を実行してそれぞれのスレッドで不要な結果を捨てなければならない）84
GPUレンダリングパイプラインの実装方法 GPUの論理モデルはAPIが提供するもので、ハードウェアベンダーによって異なる
頂点シェーダーは完全にプログラマブル テッセレーションは完全にプログラマブル
（プリミティブ（点、直線、三角形）の頂点に作用） テッセレーション・ジオメトリーシェーダーはオプション
（モバイルデバイスではプログラマブルでない場合もある） クリッピングは固定機能ハードウェアで実装される スクリーンマッピングは単純なスケールと再配置を行う
（ウィンドウとビューポートの設定による） 三角形セットアップ・三角形トラバースは固定機能ハードウェアで実装される ピクセルシェーダーは完全にプログラマブル マージはプログラマブルではないが高度に設定可能
（色、z-バッファ、ブレンド、ステンシルなどのバッファの修正） プログラマブルシェーダー 統合型シェーダーデザインは、「頂点、ピクセル、ジオメトリ、テッセレーション」に関するシェーダーが共通のプログラミングモデルを共有することを意味する（内部で同じ命令セットアーキテクチャ（ISA : Instruction Set Architecture）をもつ）
DirectXでは共通シェーダーコアが統合シェーダーアーキテクチャをもつ
シェーダープロセッサが様々な役割に使用可能であり、GPUは統合シェーダーコアによって負荷のバランスを調整することができる （例：四角形ポリゴンセットよりも三角形ポリゴンセットのほうが多くの頂点シェーダー処理が必要）
シェーダーはシェーディング言語（DirectXはHLSL、OpenGLはGLSL、NVIDIA社のCg）を使ってプログラムが可能である
HLSLは中間表現として中間言語（ILまたはDXIL）というシェーダー仮想機械のバイトコードにコンパイルしてGPUのISAに変換する
ドローコールはグラフィクスAPIを起動してグラフィクスパイプラインとシェーダーを実行させる
プログラマブルシェーダーのステージの入力には、ドローコール中は変化しない一様入力とドローコール中に変化する可変入力がある （例：テクスチャは色データの配列であり変化しないため一様入力） （例：三角形の頂点やラスタライズから発生するデータは変化するため可変入力）</description>
    </item>
    
    <item>
      <title>CMakeについてのメモ [Memo #002]</title>
      <link>https://nishihi6.github.io/blog/posts/memo_cmake_01/</link>
      <pubDate>Tue, 29 Aug 2023 15:43:33 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/memo_cmake_01/</guid>
      <description>CV・CG系のライブラリはCMakeを使って開発されていることが多く、今後CMakeを頻繁に利用することが考えられるため、その使い方をまとめておく
CMakeの仕組み C/C++のビルドの仕組みとライブラリの使用方法 参考サイト（１）：https://qiita.com/seriru13/items/c2f5192615162c4c3f47 参考サイト（２）：https://kamino.hatenablog.com/entry/c%2B%2B-principle-of-build-library
コマンドラインでのビルドとCMakeでのビルドを比較 参考サイト（３）：https://qiita.com/shohirose/items/45fb49c6b429e8b204ac
実行ファイルの作成 静的・共有ライブラリの作成 サブディレクトリのソース 参考サイト（４）：https://qiita.com/shohirose/items/637f4b712893764a7ec1
コンパイルオプションの設定 ビルドタイプの指定 ジェネレーター式 ライブラリのリンク 参考サイト（５）：https://qiita.com/shohirose/items/d2b9c595a37b27ece607
他のライブラリの利用 実際にCMakeを利用する 参考サイト（６）：https://kamino.hatenablog.com/entry/cmake_tutorial1
CMakeのインストール Configurate &amp;amp; Generate ビルド デバッグ 参考サイト（７）：https://kamino.hatenablog.com/entry/cmake_tutorial2
階層化 参考サイト（８）：https://kamino.hatenablog.com/entry/cmake_tutorial3
CMakeプロジェクトの設定 ビルドタイプの設定 参考サイト（９）：https://kamino.hatenablog.com/entry/cmake_tutorial4
find_package 外部ライブラリの利用 外部ライブラリ利用の手順 例として、数理最適化ライブラリceres-solverとその依存ライブラリEigenとglogを利用
Eigenのインストール EigenのGitHubリポジトリをクローン
手動インストールのためC:\lib\eigen3.3.7にビルド
（git clone https://github.com/eigenteam/eigen-git-mirror.git）※今回はsourcetreeを利用 cd eigen-git-mirror git checkout 3.3.7 mkdir build cd build cmake .. -DCMAKE_INSTALL_PREFIX=&amp;#39;C:/lib/eigen3.3.7&amp;#39; cmake --build . --target install Glogのインストール GlogのGitHubリポジトリをクローン
手動インストールのためC:\lib\glog0.4.0にビルド
（git clone https://github.com/eigenteam/eigen-git-mirror.git）※今回はsourcetreeを利用 cd eigen-git-mirror git checkout 3.3.7 mkdir build cd build cmake .</description>
    </item>
    
    <item>
      <title>メモリンク集 [Memo #001]</title>
      <link>https://nishihi6.github.io/blog/posts/memo_links_01/</link>
      <pubDate>Mon, 28 Aug 2023 21:43:10 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/memo_links_01/</guid>
      <description>私用メモ CMakeについてのメモ [Memo #002] https://nishihi6.github.io/blog/posts/memo_links_01/</description>
    </item>
    
    <item>
      <title>DirectX12の描画処理 #3 [Devlog #004]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_dx12_03/</link>
      <pubDate>Sun, 27 Aug 2023 21:44:55 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_dx12_03/</guid>
      <description>DirectX12を使った描画処理 DirectX12の環境構築 初期化 Direct3D (D3D) Direct3D(D3D)とは、DirectXの中の3DグラフィクスAPIの一部であり、多様なグラフィクスハードウェア上でハードウェアアクセラレーションを活用したグラフィクスの表示や操作を行うことができる
D3D12Deviceは、D3D12(Direct3D 12)のインターフェースの一つで、グラフィクスハードウェアへの低レベルのアクセスを提供し、リソースの作成やコマンドのキューの管理などの主要な機能をもつ
DirectX Graphics Infrastructure (DXGI) DXGIとは、DirectXのコンポーネントの一つであり、アダプター（グラフィクスカード）、モニター、フレームバッファなどのリソース管理や、スワップチェーンの操作などのタスクを行う DXGIは、Direct3Dが多様なグラフィクスハードウェア上で一貫して動作するための基盤となる
DXGIFactoryは、DXGIの中でも主要なインターフェースの一つで、アダプター（グラフィクスカード）やモニターの情報を取得したり、スワップチェーンを作成するためのメソッドを提供する
デバイスの初期化 D3D12DeviceとDXGIFactoryは初期化に最低限必要になる
リンクするライブラリファイルd3d12.libとdxgi.libをソースコード内の記述でリンクして、d3d12.hとdxgi1_6.hをインクルードする
// stdafx.h // D3D12 #pragma comment(lib,&amp;#34;d3d12.lib&amp;#34;) #pragma comment(lib,&amp;#34;dxgi.lib&amp;#34;) #include &amp;lt;d3d12.h&amp;gt; #include &amp;lt;dxgi1_6.h&amp;gt; GraphicsフォルダにGraphicsDevice.hとGraphicsDevice.cppを追加
dev-dx12-202308（プロジェクト名） └─ Source ├─ Application │ ├─ Application.h │ └─ Application.cpp ├─ Graphics │ ├─ GraphicsDevice.h │ └─ GraphicsDevice.cpp ├─ System │ ├─ Utility │ │ ├─ Utility.h │ │ └─ Utility.cpp │ ├─ Window │ │ ├─ Window.h │ │ └─ Window.</description>
    </item>
    
    <item>
      <title>DirectX12の描画処理 #2 [Devlog #003]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_dx12_02/</link>
      <pubDate>Sat, 26 Aug 2023 18:46:37 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_dx12_02/</guid>
      <description>DirectX12を使った描画処理 環境構築の続き プリコンパイル済みヘッダーの追加 Sourceフォルダ以下にstdafx.hとstdafx.cppと追加
dev-dx12-202308（プロジェクト名） └─ Source ├─ Application │ ├─ Application.h │ └─ Application.cpp ├─ Graphics ├─ System │ └─ Window │ ├─ Window.h │ └─ Window.cpp ├─ stdafx.h └─ stdafx.cpp プロジェクトのプロパティの設定からプリコンパイル済みヘッダーを使用(/Yu)に設定（プリコンパイル済みヘッダーファイルはstdafx.h）
プロジェクトのプロパティの設定から必ず使用されるインクルードファイルにstdafx.hを追加設定
追加したstdafx.cppのプロパティの設定からプリコンパイル済みヘッダーを作成(/Yc)に設定（プリコンパイル済みヘッダーファイルはstdafx.h）
以下コード
// stdafx.h #pragma once // 基本 #pragma comment(lib,&amp;#34;winmm.lib&amp;#34;) #define NOMINMAX #include &amp;lt;Windows.h&amp;gt; #include &amp;lt;iostream&amp;gt; #include &amp;lt;cassert&amp;gt; #include &amp;lt;wrl/client.h&amp;gt; // STL #include &amp;lt;map&amp;gt; #include &amp;lt;unordered_map&amp;gt; #include &amp;lt;unordered_set&amp;gt; #include &amp;lt;string&amp;gt; #include &amp;lt;array&amp;gt; #include &amp;lt;vector&amp;gt; #include &amp;lt;stack&amp;gt; #include &amp;lt;list&amp;gt; #include &amp;lt;iterator&amp;gt; #include &amp;lt;queue&amp;gt; #include &amp;lt;algorithm&amp;gt; #include &amp;lt;memory&amp;gt; #include &amp;lt;random&amp;gt; #include &amp;lt;fstream&amp;gt; #include &amp;lt;iostream&amp;gt; #include &amp;lt;sstream&amp;gt; #include &amp;lt;functional&amp;gt; #include &amp;lt;thread&amp;gt; #include &amp;lt;atomic&amp;gt; #include &amp;lt;mutex&amp;gt; #include &amp;lt;future&amp;gt; #include &amp;lt;fileSystem&amp;gt; #include &amp;lt;chrono&amp;gt; #define _USE_MATH_DEFINES #include &amp;lt;math.</description>
    </item>
    
    <item>
      <title>CG理論 #1 レンダリングパイプライン [Devlog #002]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_cg_01/</link>
      <pubDate>Thu, 24 Aug 2023 15:22:11 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_cg_01/</guid>
      <description>CG屋さんのバイブル：Real Time Rendering Fourth Edition を読んで理解したことについてを要約します（内容の転載を避け、詳しく説明しすぎないように配慮します）
レンダリングパイプライン レンダリングパイプラインの主な機能は、視点（仮想カメラ）、光源、３次元オブジェクトから２次元イメージをレンダーすること
（２次元イメージ中の）オブジェクトの位置と形を決定するもの
幾何学形状（ジオメトリ） 環境特性 カメラ配置 （２次元イメージ中の）オブジェクトの見た目を決定するもの
マテリアル特性 光源 表面テクスチャ シェーディングの式 アーキテクチャ レンダリングパイプラインはいくつかのステージからなり1、スピードアップを主な目的として並列に実行される
主なステージ（各々でさらにいくつかのサブステージで構成される）
アプリケーション（衝突検出、アニメーション、物理シミュレーションなど） ジオメトリ処理（座標変換、投影などの幾何学的処理） ラスタライズ（3つの頂点から三角形の内側のピクセルを求める） ピクセル処理（ピクセル単位での処理（色や深度など）） フレーム間に実行する計算の複雑さによってフレーム/秒が変化し、これによりレンダリングの性能を表すことが一般的
アプリケーション 開発者はこのアプリケーションステージで何が起こるのかを制御する
アプリによって一番の違いが見られるのはレンダリングパイプラインの中でもこのアプリケーションステージであると思われる
アプリケーションの作業は基本的にCPU上で実行するが、コンピュートシェーダーを使ってGPU上で実行することもある
レンダーすべきジオメトリ（点、直線、三角形）をジオメトリ処理ステージに渡すのが主なタスク
ユーザからの入力情報を扱ったり、描画する必要がないポリゴンを求めるカリングアルゴリズムを実行したりと様々な処理を行う
[DX12] Input-Assembler（頂点情報やインデックス情報の入力） Input-Assembler（入力アセンブラー）は頂点情報だけではなく、&amp;ldquo;どの3頂点を組み合わせて三角形を作るのか&amp;quot;という情報などが入力されるステージ
ポリゴンの表示のためには、数値（バイトの塊）を解釈するための頂点レイアウトとインデックス情報、そしてもちろん頂点情報（バイトの塊）が入力情報として必要になる
ジオメトリ処理 ジオメトリ処理ステージでは、幾何学形状（ジオメトリ）を三角形単位と頂点単位で操作する
ジオメトリ処理ステージのサブステージ（機能ステージ）
頂点シェーディング 投影 クリッピング スクリーンマッピング 頂点シェーディング 頂点シェーディングでは、頂点位置を計算し、頂点出力データにもたせる法線やテクスチャ座標などを評価する
頂点シェーダーのもともとの仕組み2
各頂点の位置と法線に光源を適用して色を計算 頂点の色を三角形上で補間 頂点シェーダーは各頂点に関連付けたデータの設定を行う
頂点の計算
モデル空間にモデルが存在（モデルのいずれかの頂点や近傍などに原点をとる） モデル変換により、モデルごとにモデル空間内での位置と向きが決まる オブジェクトはモデル座標（＝ローカル座標：モデル空間の座標）をもち、モデル変換が適用されると、ワールド空間内でのワールド座標が決まる カメラ空間での頂点の計算
ビュー変換により、カメラを原点としたカメラ空間での座標が決まる
（視線がZ軸（負or正）方向、上がY軸、右がX軸 ※API依存） モデル変換とビュー変換のいずれも4×4行列として実装できる
シェーディング
シェーディングでは、各オブジェクトのマテリアルとそれを照らす光源による効果を決定する見た目のモデル化を行う
各点におけるシェーディングの式の計算は、ジオメトリ処理の間に行うものもあれば、ピクセル単位の処理で行うものもある
続くステージに出力する色、ベクトル、テクスチャ座標、その他のシェーディングデータは、頂点ごとに格納されたマテリアルデータ（点の位置、色、シェーディング式の評価に必要な数値情報など）を用いて算出される
投影からクリッピングへ
正準ビューボリュームは、端点が(-1,-1,-1)と(1,1,1)にある単位立方体で、0 &amp;lt;= z &amp;lt;= 1等のボリュームを使って定義される
頂点シェーダーが行う投影
正投影（平行投影） -&amp;gt; 直方体のから単位立方体に変換 透視投影 -&amp;gt; ピラミッド形状の錐台から単位立方体に変換 その他：斜投影や不等角投影など 変換はいずれも4×4行列として実装できる</description>
    </item>
    
    <item>
      <title>DirectX12の描画処理 #1 [Devlog #001]</title>
      <link>https://nishihi6.github.io/blog/posts/devlog_dx12_01/</link>
      <pubDate>Wed, 23 Aug 2023 01:19:34 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/devlog_dx12_01/</guid>
      <description>DirectX12を使った描画処理 環境構築 VisualStudio2022でプロジェクトの作成 (新規作成-&amp;gt;プロジェクト-&amp;gt;)新しいプロジェクトの作成-&amp;gt;空のプロジェクト プロジェクト名（ソリューション名）と保存パスを指定 &amp;ldquo;ソリューションとプロジェクトを同じディレクトリに配置する&amp;quot;にチェック 作成 ソリューションのプロパティを変更 構成プロパティ-&amp;gt;リンカー-&amp;gt;システム-&amp;gt;サブシステム &amp;ldquo;コンソール&amp;quot;から&amp;quot;Windows&amp;quot;に変更 以下のようにフォルダを構成 新しいフォルダを作成 フォルダに新しい項目を追加（以降説明省略） Applicationフィルターに新しい項目を追加 .cpp 名前：Application.cpp 場所：Source/Application（フォルダを作成） .h 名前：Application.h 場所：Source/Application dev-dx12-202308（プロジェクト名） └─ Source ├─ Application │ ├─ Application.h │ └─ Application.cpp └─ Graphics Application.h Applicationクラス ウィンドウ作成の実行を行うExecute()関数を宣言
Applicationクラスオブジェクトを生成するInstance()関数を定義する（シングルトン：クラスのインスタンスが１つしか存在しないことを保証する）
// Application.h // Applicationクラス class Application { public: void Execute(); static Application&amp;amp; Instance() { static Application instance; return instance; } private: Window m_window; Application() {} } Application.cpp Windows.hのインクルード WindowsプログラムのためにWindows.hをインクルード（Windowsプログラムの型や構造体、定数、ファンクションコールが定義されている） （※Windows.hとWindow.hの混同に注意）
Windowsプログラムにmain()関数は無く、WinMain()関数からプログラムが開始される
WinMain()関数 WINAPIはWindows.hでWin32 API 関数を呼び出すときの規約として定義される。#define WINAPI __stdcall</description>
    </item>
    
    <item>
      <title>My First Post（記事作成に関する備忘録）</title>
      <link>https://nishihi6.github.io/blog/posts/my-first-post/</link>
      <pubDate>Tue, 22 Aug 2023 06:05:10 +0900</pubDate>
      
      <guid>https://nishihi6.github.io/blog/posts/my-first-post/</guid>
      <description>&lt;p&gt;Hello world! It&amp;rsquo;s me!&lt;/p&gt;
 &lt;img src=&#34;../img/itsme.jpg&#34; width=&#34;200px&#34;&gt;
&lt;p&gt;以下、記事作成のマニュアル&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://nishihi6.github.io/blog/pages/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nishihi6.github.io/blog/pages/about/</guid>
      <description>このページはポートフォリオ（仮）として利用する予定です。
略歴 学業（修士課程25卒）芝浦工業大学（工学部情報工学科） 2019/4~芝浦工業大学大学院（電気電子情報工学科） 2023/4~Interactive Graphics Research Group（井尻研究室） 2022/4~研究分野Computer Vision、Computer Graphics研究キーワード微分可能レンダリング、フォトグラメトリ、マテリアルの反射特性推定と再構成研究業績2022/02 画像電子学会（講演）邱 雨澄, 西田 拓央, 井尻 敬. 直線光源による質感を含めた微小物体のデジタルデータ化手法. 画像電子学会研究会講演予稿, 21.03 (0), 116-122, 2022． https://cir.nii.ac.jp/crid/1390014128339861888
2022/10 VC+VCC 2022（Poster [P4]）VCポスター賞受賞籔本 悠紀, 西田 拓央, 小檜山賢二, 井尻 敬. Neural Radiance Fieldsの昆虫標本のデジタルデータ化への応用に関する検討. VC+VCC 2022, 2022年10月6日． https://visualcomputing.jp/vc2022/program/poster/
2022/10 VC+VCC 2022（Poster [P29]）西田 拓央, 小檜山賢二, 井尻 敬. 直線光源環境下における鏡面反射成分分離を用いた昆虫標本の反射特性推定. VC+VCC 2022, 2022年10月7日． https://visualcomputing.jp/vc2022/program/poster/
2023/01 日本画像学会（学会誌 解説論文）小檜山 賢二, 西田 拓央, 井尻 敬.</description>
    </item>
    
  </channel>
</rss>
